{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cr5T-8V9quXl"},"source":["# **Lab 1.1 Text Preprocessing**"]},{"cell_type":"markdown","metadata":{"id":"F-5yRklvm8is"},"source":["In this lab session, you will learn reexplore some important tasks in text preprocessing. This will include tokenization, normalization, stopword removal and stemming/lemmatization. "]},{"cell_type":"markdown","metadata":{"id":"WTRaPAz-pWWY"},"source":["## **Tokenizer**\n","Tokenization is essentially splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms. Each of these smaller units are called tokens.\n","\n","Tokenizers can be used to divide strings into lists of substrings. For example, Sentence tokenizer can be used to find the list of sentences and Word tokenizer can be used to find the list of words in strings.\n"]},{"cell_type":"markdown","metadata":{"id":"1G6zCAC5qpH4"},"source":["**Sentence Tokenizer**\n","\n","- breaks text paragraph into sentences\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"C650QTo1rWEQ"},"source":["**Word tokenizer**\n","\n","- breaks text paragraph into words\n"]},{"cell_type":"markdown","metadata":{"id":"Q5jyjeXYrkbw"},"source":["**How to sentence tokenize in NLTK**"]},{"cell_type":"code","metadata":{"id":"bXuL0vm0DwD9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666682038599,"user_tz":-480,"elapsed":734,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"7c3d1df9-2ea7-4df0-e8fd-1b29c068f48c"},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["from nltk.tokenize import sent_tokenize"],"metadata":{"id":"NabyxUie4e9M","executionInfo":{"status":"ok","timestamp":1666682038600,"user_tz":-480,"elapsed":28,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"NN76Dl5RC_CR","executionInfo":{"status":"ok","timestamp":1666682038601,"user_tz":-480,"elapsed":29,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}}},"source":["text = 'this’s a sent tokenize test. this is sent two. is this sent three? sent 4 is cool! Now it’s your turn.'\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"44mYXeRhDEiq","executionInfo":{"status":"ok","timestamp":1666682038601,"user_tz":-480,"elapsed":29,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}}},"source":["sent_tokenize_list = sent_tokenize(text) #tokenizing the sentence"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"XJtVBTXUDMVU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666682038602,"user_tz":-480,"elapsed":29,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"d58d7b58-8f53-4cc4-c27b-ebc4fa8276d3"},"source":["sent_tokenize_list"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['this’s a sent tokenize test.',\n"," 'this is sent two.',\n"," 'is this sent three?',\n"," 'sent 4 is cool!',\n"," 'Now it’s your turn.']"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"VzW5pRUKELBz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666682038602,"user_tz":-480,"elapsed":26,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"8ad0b388-4219-4660-ab93-79f8c5e8cc6b"},"source":["len(sent_tokenize_list) #length of the sentences"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"-DrXDvLnTbpk"},"source":["**Tokenizing text into words**\n"]},{"cell_type":"markdown","metadata":{"id":"oKZVOc62U-F7"},"source":["Need to call **word_tokenize** from **nltk.tokenize** module:\n"]},{"cell_type":"code","metadata":{"id":"BREtWoXMCWHM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666682038603,"user_tz":-480,"elapsed":25,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"35d9e711-0b66-4094-8396-d913f278446c"},"source":["from nltk.tokenize import word_tokenize\n","\n","word_tokenize(\"Hello World.\")\n"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hello', 'World', '.']"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"B3WcFZLOC3u-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666682038603,"user_tz":-480,"elapsed":23,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"4a102914-228f-4ff5-93c3-9bd0d53ac5d1"},"source":["word_tokenize(\"They aren't the best for O'Neill's team!\") #tokenizing each word and symbols in the sentence"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['They', 'are', \"n't\", 'the', 'best', 'for', \"O'Neill\", \"'s\", 'team', '!']"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"wKZMIc7gKRWW"},"source":["Try again with other sentences and observe the output.\n"]},{"cell_type":"markdown","metadata":{"id":"3KOvRhpuKaZB"},"source":["# **Stopword Removal**\n","Stopwords are the most common words in any natural language like the words *a, the* and *is*. For the purpose of analyzing text data and building NLP models, these stopwords might not add much value to the meaning of the document and it should be removed."]},{"cell_type":"markdown","metadata":{"id":"rj9YJwxjLQx3"},"source":["Let’s see what are the English stopwords available in nltk\n"]},{"cell_type":"code","metadata":{"id":"9vQdCzDmOeWj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666682038603,"user_tz":-480,"elapsed":20,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"3bbdd827-85f0-4ca5-a97e-8f3ba16ed878"},"source":["\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","stop_words = set(stopwords.words(\"english\"))\n","print(stop_words)\n"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["{'it', 'after', 'during', 're', 'shan', 'and', 'above', 'in', 'couldn', 'which', 'no', 'myself', 'nor', 'didn', 'his', \"wouldn't\", 'wasn', 'weren', 'few', 'down', 'any', \"mustn't\", 'on', 'own', 'mustn', 'she', 'only', 'itself', 'its', \"it's\", 'than', 'will', 'themselves', 'what', 'most', 'now', \"shouldn't\", 'each', 'between', 'that', 'further', 'needn', 'as', 've', 'when', 'through', \"aren't\", 'too', 'where', 'yours', 'were', \"wasn't\", 'been', 'do', 'wouldn', \"you're\", 'same', 'don', 'those', 'below', 'if', 'can', 'ma', 'other', 'the', 'for', 'herself', 'under', 'while', 'off', 'm', 'shouldn', 'hers', 'then', 'more', 'y', 'there', 'being', 'theirs', \"shan't\", 'them', \"isn't\", 'he', 'himself', 'was', 'aren', \"haven't\", 'of', 'about', \"mightn't\", 'both', \"needn't\", 'have', \"that'll\", 'had', \"couldn't\", 'her', 'yourself', 'ain', 'who', 'at', 'yourselves', \"didn't\", 'why', 'i', 'over', 'with', 'but', 'me', 'did', 's', 'is', 'once', 'up', \"doesn't\", 'has', 'isn', \"you'll\", 'whom', 'to', 't', 'does', 'again', 'out', 'my', \"weren't\", 'so', \"hasn't\", 'some', \"hadn't\", 'by', 'won', 'our', 'doesn', 'haven', 'these', 'you', \"won't\", 'your', 'before', 'how', 'we', 'll', 'should', 'd', \"should've\", 'are', 'they', 'him', 'just', 'ours', 'hadn', 'against', 'o', 'hasn', 'ourselves', \"you've\", 'mightn', 'their', 'this', 'all', \"don't\", 'such', 'doing', 'a', 'very', \"she's\", 'be', 'from', 'an', 'here', 'having', 'into', 'because', 'until', 'am', \"you'd\", 'not', 'or'}\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","metadata":{"id":"AcC5X3DEPVav"},"source":["Let’s see how stop word removal can be done using the corpus module. Observe what words are being removed here. \n"]},{"cell_type":"code","metadata":{"id":"WFdFI1vtuqm9","outputId":"52216eed-ea55-4294-9676-dd8679c22892","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666682038604,"user_tz":-480,"elapsed":19,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}}},"source":["#import nltk\n","#from nltk.corpus import stopwords\n","#from nltk.tokenize import word_tokenize \n","#set(stopwords.words('english'))\n","\n","\n","# credits to Analytics Vidhya\n","#sample sentence\n","text = \"\"\"NLTK supports stop word removal, and you can find the list of stop words in the corpus module. \n","To remove stop words from a sentence, you can divide your text into words and then remove the word if it exits \n","in the list of stop words provided by NLTK.\"\"\"\n","\n","# set of stop words\n","stop_words = set(stopwords.words('english')) \n","# tokens of words  \n","word_tokens = word_tokenize(text) \n","    \n","filtered_sentence = [] \n","  \n","for w in word_tokens: \n","    if w not in stop_words: \n","        filtered_sentence.append(w) \n","\n","\n","\n","print(\"\\n\\nOriginal Sentence \\n\\n\")\n","print(\" \".join(word_tokens)) \n","\n","print(\"\\n\\nFiltered Sentence \\n\\n\")\n","print(\" \".join(filtered_sentence))"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Original Sentence \n","\n","\n","NLTK supports stop word removal , and you can find the list of stop words in the corpus module . To remove stop words from a sentence , you can divide your text into words and then remove the word if it exits in the list of stop words provided by NLTK .\n","\n","\n","Filtered Sentence \n","\n","\n","NLTK supports stop word removal , find list stop words corpus module . To remove stop words sentence , divide text words remove word exits list stop words provided NLTK .\n"]}]},{"cell_type":"markdown","metadata":{"id":"6RQOH9oU0TDG"},"source":["# **Normalization**\n"]},{"cell_type":"markdown","metadata":{"id":"3b-Mkg_zc8bc"},"source":["For certain tasks, one of the simplest form of normalization is converting the text into lowercase letters (where capitalization is not important -for example in text classification). Others would include stemming or lemmatization to reduce a word into its canonical form. "]},{"cell_type":"markdown","metadata":{"id":"bmoh9AVsjCu_"},"source":["Let's have a look on how the text can be converted into lowercase by defining a function: "]},{"cell_type":"code","metadata":{"id":"8vwqtPhOjibn","executionInfo":{"status":"ok","timestamp":1666682038604,"user_tz":-480,"elapsed":17,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}}},"source":["def changetolower(text):\n","    lowerText = text.lower()\n","    print(\"Before:\",text)\n","    print(\"After:\",lowerText)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"nH9IJwu2j1ON","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666682038604,"user_tz":-480,"elapsed":17,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"d5c39877-5ca5-454c-ed70-2d4ebf8ba7c8"},"source":["changetolower(\"Bandar Baru Bangi is a town in Selangor\")"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Before: Bandar Baru Bangi is a town in Selangor\n","After: bandar baru bangi is a town in selangor\n"]}]},{"cell_type":"markdown","metadata":{"id":"5rlWESGGknvE"},"source":["# **Stemming**"]},{"cell_type":"markdown","metadata":{"id":"t66YNsrWkr4i"},"source":["Stemming is the process of reducing inflection in words (e.g. troubled, troubles) to their root form (e.g. trouble). There are different algorithms for stemming. The most common algorithm, which is also known to be empirically effective for English, is Porters Algorithm. NLTK provides a variation of stemmers, so let's try and observe the output for each of them."]},{"cell_type":"code","metadata":{"id":"X0xa_s2WpYuA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666682038605,"user_tz":-480,"elapsed":15,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"01132726-5c58-4809-ff95-8a87b08f524b"},"source":["import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem import PorterStemmer\n","from nltk.stem import LancasterStemmer\n","from nltk.corpus import stopwords\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"F94y1K9Asl2q","executionInfo":{"status":"ok","timestamp":1666682038605,"user_tz":-480,"elapsed":13,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}}},"source":["def mystemmer(myword):\n","    stemmer1 = PorterStemmer()\n","    print(\"Porter Stemmer's output:\", stemmer1.stem(myword))\n","    stemmer2 = LancasterStemmer()\n","    print(\"Lancester Stemmer's output:\", stemmer2.stem(myword))"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5AWQisPfs794"},"source":["Observe the output and try with other words.."]},{"cell_type":"code","metadata":{"id":"BROHniiYtFTe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666682038605,"user_tz":-480,"elapsed":13,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"63abc1ec-17f6-4172-a185-ef31938b36bc"},"source":["mystemmer('ponies')"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Porter Stemmer's output: poni\n","Lancester Stemmer's output: pony\n"]}]},{"cell_type":"markdown","metadata":{"id":"l9tdKX51tiwF"},"source":["# **Lemmatizer**"]},{"cell_type":"markdown","metadata":{"id":"yVBnUH58trYq"},"source":["Lemmatization is very similar to stemming, where the goal is to remove inflections and map a word to its root form. The only difference is that, lemmatization doesn’t just chop things off, it actually transforms words to the actual root. For example, the word “better” would map to “good”. It may use a dictionary such as WordNet for mappings or some special rule-based approaches. Here is an example of lemmatization in action using a WordNet-based approach in NLTK:"]},{"cell_type":"code","metadata":{"id":"vlU0tT4uua12","executionInfo":{"status":"ok","timestamp":1666682038606,"user_tz":-480,"elapsed":12,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}}},"source":["def mylemma(myword): # function for lemmatization\n","    lemmatizer = WordNetLemmatizer() #this lemmatizer uses WordNet as the dictionary/lexical resource\n","    print(lemmatizer.lemmatize(myword)) \n","    "],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"QsoiU5bNva5M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666682039962,"user_tz":-480,"elapsed":1369,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"537ce573-4aa2-4fe1-8f0d-d10f9a341c8e"},"source":["mylemma('flies')"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["fly\n"]}]},{"cell_type":"markdown","source":["Try the lemmatizer with other words such as 'computerization' or 'flies'"],"metadata":{"id":"IU5lPsraNFsa"}},{"cell_type":"markdown","metadata":{"id":"6fU9NDgWv5t2"},"source":["# **LAB TASK 1**"]},{"cell_type":"markdown","metadata":{"id":"tIAp2E2KxL_T"},"source":["Given the text below:\n","\n","During the heat of the space race in the 1960's, NASA quickly discovered that ballpoint pens would not work in the zero gravity confines of its space capsules. After considerable research and development, the Astronaut Pen was developed at a cost of $1 million. The pen worked in zero gravity, upside down, underwater, on almost any surface including glass and also enjoyed some modest success as a novelty item back here on earth. The Soviet Union, when faced with the same problem, used a pencil. This has to be the funniest joke ever.\n","\n","\n","Write a program that performs the task as follows:\n","\n","1.   toknenize the text\n","2.   remove the stopwords\n","3.   change the text into lowercase\n","4.   perform stemming/lemmatization \n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jI0F9wEiz1Tn"},"source":["Submit your lab task in UKMFolio by 28 October 2022 (Friday). Make sure to include your name and matric number.  "]},{"cell_type":"markdown","metadata":{"id":"J8nF2gqf0iIV"},"source":["# **NAME: CHONG WEI YI**\n","\n","# **MATRIC NO: A180497**"]},{"cell_type":"markdown","source":["**1.1 Tokenization**"],"metadata":{"id":"ENSfYiDt3DWW"}},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","\n","text = \"During the heat of the space race in the 1960's, NASA quickly discovered that ballpoint pens would not work in the zero gravity confines of its space capsules. After considerable research and development, the Astronaut Pen was developed at a cost of $1 million. The pen worked in zero gravity, upside down, underwater, on almost any surface including glass and also enjoyed some modest success as a novelty item back here on earth. The Soviet Union, when faced with the same problem, used a pencil. This has to be the funniest joke ever.\"\n","word_tokenize(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jx4l3Ypl7PkI","executionInfo":{"status":"ok","timestamp":1666682039964,"user_tz":-480,"elapsed":24,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"cd521d2a-0801-4525-e6fa-564b57b1500b"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['During',\n"," 'the',\n"," 'heat',\n"," 'of',\n"," 'the',\n"," 'space',\n"," 'race',\n"," 'in',\n"," 'the',\n"," '1960',\n"," \"'s\",\n"," ',',\n"," 'NASA',\n"," 'quickly',\n"," 'discovered',\n"," 'that',\n"," 'ballpoint',\n"," 'pens',\n"," 'would',\n"," 'not',\n"," 'work',\n"," 'in',\n"," 'the',\n"," 'zero',\n"," 'gravity',\n"," 'confines',\n"," 'of',\n"," 'its',\n"," 'space',\n"," 'capsules',\n"," '.',\n"," 'After',\n"," 'considerable',\n"," 'research',\n"," 'and',\n"," 'development',\n"," ',',\n"," 'the',\n"," 'Astronaut',\n"," 'Pen',\n"," 'was',\n"," 'developed',\n"," 'at',\n"," 'a',\n"," 'cost',\n"," 'of',\n"," '$',\n"," '1',\n"," 'million',\n"," '.',\n"," 'The',\n"," 'pen',\n"," 'worked',\n"," 'in',\n"," 'zero',\n"," 'gravity',\n"," ',',\n"," 'upside',\n"," 'down',\n"," ',',\n"," 'underwater',\n"," ',',\n"," 'on',\n"," 'almost',\n"," 'any',\n"," 'surface',\n"," 'including',\n"," 'glass',\n"," 'and',\n"," 'also',\n"," 'enjoyed',\n"," 'some',\n"," 'modest',\n"," 'success',\n"," 'as',\n"," 'a',\n"," 'novelty',\n"," 'item',\n"," 'back',\n"," 'here',\n"," 'on',\n"," 'earth',\n"," '.',\n"," 'The',\n"," 'Soviet',\n"," 'Union',\n"," ',',\n"," 'when',\n"," 'faced',\n"," 'with',\n"," 'the',\n"," 'same',\n"," 'problem',\n"," ',',\n"," 'used',\n"," 'a',\n"," 'pencil',\n"," '.',\n"," 'This',\n"," 'has',\n"," 'to',\n"," 'be',\n"," 'the',\n"," 'funniest',\n"," 'joke',\n"," 'ever',\n"," '.']"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["***1.2Stopwords Removal***"],"metadata":{"id":"P6V31cdA4vma"}},{"cell_type":"code","metadata":{"outputId":"6c9b2d3b-087d-464e-c81d-d72c9059f3dd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666682039965,"user_tz":-480,"elapsed":23,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"id":"9XIEdZVZ448W"},"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize \n","set(stopwords.words('english'))\n","\n","text = \"During the heat of the space race in the 1960's, NASA quickly discovered that ballpoint pens would not work in the zero gravity confines of its space capsules. After considerable research and development, the Astronaut Pen was developed at a cost of $1 million. The pen worked in zero gravity, upside down, underwater, on almost any surface including glass and also enjoyed some modest success as a novelty item back here on earth. The Soviet Union, when faced with the same problem, used a pencil. This has to be the funniest joke ever.\"\n","\n","# set of stop words\n","stop_words = set(stopwords.words('english'))\n","word_tokens = word_tokenize(text) \n","    \n","filtered_sentence = [] \n","  \n","for w in word_tokens: \n","    if w not in stop_words: \n","        filtered_sentence.append(w) \n","\n","\n","\n","print(\"\\n\\nOriginal Sentence \\n\\n\")\n","print(\" \".join(word_tokens)) \n","\n","print(\"\\n\\nFiltered Sentence \\n\\n\")\n","print(\" \".join(filtered_sentence))"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Original Sentence \n","\n","\n","During the heat of the space race in the 1960 's , NASA quickly discovered that ballpoint pens would not work in the zero gravity confines of its space capsules . After considerable research and development , the Astronaut Pen was developed at a cost of $ 1 million . The pen worked in zero gravity , upside down , underwater , on almost any surface including glass and also enjoyed some modest success as a novelty item back here on earth . The Soviet Union , when faced with the same problem , used a pencil . This has to be the funniest joke ever .\n","\n","\n","Filtered Sentence \n","\n","\n","During heat space race 1960 's , NASA quickly discovered ballpoint pens would work zero gravity confines space capsules . After considerable research development , Astronaut Pen developed cost $ 1 million . The pen worked zero gravity , upside , underwater , almost surface including glass also enjoyed modest success novelty item back earth . The Soviet Union , faced problem , used pencil . This funniest joke ever .\n"]}]},{"cell_type":"markdown","source":["***1.3 Lowercase***"],"metadata":{"id":"XrGrM_Tf7pNP"}},{"cell_type":"code","metadata":{"executionInfo":{"status":"ok","timestamp":1666682039966,"user_tz":-480,"elapsed":19,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"mgRicT5a5j6W","outputId":"8b6fd616-c422-4258-c996-d0cd6d3d5e12"},"source":["def changetolower(text):\n","    lowerText = text.lower()\n","    print(\"Before:\",text)\n","    print(\"After:\",lowerText)\n","  \n","changetolower(\" \".join(filtered_sentence))"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Before: During heat space race 1960 's , NASA quickly discovered ballpoint pens would work zero gravity confines space capsules . After considerable research development , Astronaut Pen developed cost $ 1 million . The pen worked zero gravity , upside , underwater , almost surface including glass also enjoyed modest success novelty item back earth . The Soviet Union , faced problem , used pencil . This funniest joke ever .\n","After: during heat space race 1960 's , nasa quickly discovered ballpoint pens would work zero gravity confines space capsules . after considerable research development , astronaut pen developed cost $ 1 million . the pen worked zero gravity , upside , underwater , almost surface including glass also enjoyed modest success novelty item back earth . the soviet union , faced problem , used pencil . this funniest joke ever .\n"]}]},{"cell_type":"markdown","source":["***1.4 Stemming/Lemmatization***"],"metadata":{"id":"W8wCterP7wBL"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666682098293,"user_tz":-480,"elapsed":511,"user":{"displayName":"CHONG WEI YI","userId":"01816057422713521367"}},"outputId":"01f22284-86ef-4fc2-97a0-bcd16612275c","id":"TAPvATAB6Ab7"},"source":["from nltk.corpus.reader import wordlist\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem import PorterStemmer\n","from nltk.stem import LancasterStemmer\n","from nltk.corpus import stopwords\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","\n","def mystemmer(myword):\n","    stemmer1 = PorterStemmer()\n","    print(\"Porter Stemmer's output:\", stemmer1.stem(myword))\n","    stemmer2 = LancasterStemmer()\n","    print(\"Lancester Stemmer's output:\", stemmer2.stem(myword))\n","\n","def mylemma(myword): # function for lemmatization\n","    lemmatizer = WordNetLemmatizer() #this lemmatizer uses WordNet as the dictionary/lexical resource\n","    print(lemmatizer.lemmatize(myword)) \n","\n","text = \" \".join(filtered_sentence).lower()\n","print(text)\n","word_token =word_tokenize(text)\n","\n","for word in word_token:\n","  mystemmer(word)\n","\n","for word in word_token:\n","  mylemma(word)\n"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["during heat space race 1960 's , nasa quickly discovered ballpoint pens would work zero gravity confines space capsules . after considerable research development , astronaut pen developed cost $ 1 million . the pen worked zero gravity , upside , underwater , almost surface including glass also enjoyed modest success novelty item back earth . the soviet union , faced problem , used pencil . this funniest joke ever .\n","Porter Stemmer's output: dure\n","Lancester Stemmer's output: dur\n","Porter Stemmer's output: heat\n","Lancester Stemmer's output: heat\n","Porter Stemmer's output: space\n","Lancester Stemmer's output: spac\n","Porter Stemmer's output: race\n","Lancester Stemmer's output: rac\n","Porter Stemmer's output: 1960\n","Lancester Stemmer's output: 1960\n","Porter Stemmer's output: 's\n","Lancester Stemmer's output: 's\n","Porter Stemmer's output: ,\n","Lancester Stemmer's output: ,\n","Porter Stemmer's output: nasa\n","Lancester Stemmer's output: nas\n","Porter Stemmer's output: quickli\n","Lancester Stemmer's output: quick\n","Porter Stemmer's output: discov\n","Lancester Stemmer's output: discov\n","Porter Stemmer's output: ballpoint\n","Lancester Stemmer's output: ballpoint\n","Porter Stemmer's output: pen\n","Lancester Stemmer's output: pen\n","Porter Stemmer's output: would\n","Lancester Stemmer's output: would\n","Porter Stemmer's output: work\n","Lancester Stemmer's output: work\n","Porter Stemmer's output: zero\n","Lancester Stemmer's output: zero\n","Porter Stemmer's output: graviti\n","Lancester Stemmer's output: grav\n","Porter Stemmer's output: confin\n","Lancester Stemmer's output: confin\n","Porter Stemmer's output: space\n","Lancester Stemmer's output: spac\n","Porter Stemmer's output: capsul\n","Lancester Stemmer's output: caps\n","Porter Stemmer's output: .\n","Lancester Stemmer's output: .\n","Porter Stemmer's output: after\n","Lancester Stemmer's output: aft\n","Porter Stemmer's output: consider\n","Lancester Stemmer's output: consid\n","Porter Stemmer's output: research\n","Lancester Stemmer's output: research\n","Porter Stemmer's output: develop\n","Lancester Stemmer's output: develop\n","Porter Stemmer's output: ,\n","Lancester Stemmer's output: ,\n","Porter Stemmer's output: astronaut\n","Lancester Stemmer's output: astronaut\n","Porter Stemmer's output: pen\n","Lancester Stemmer's output: pen\n","Porter Stemmer's output: develop\n","Lancester Stemmer's output: develop\n","Porter Stemmer's output: cost\n","Lancester Stemmer's output: cost\n","Porter Stemmer's output: $\n","Lancester Stemmer's output: $\n","Porter Stemmer's output: 1\n","Lancester Stemmer's output: 1\n","Porter Stemmer's output: million\n","Lancester Stemmer's output: mil\n","Porter Stemmer's output: .\n","Lancester Stemmer's output: .\n","Porter Stemmer's output: the\n","Lancester Stemmer's output: the\n","Porter Stemmer's output: pen\n","Lancester Stemmer's output: pen\n","Porter Stemmer's output: work\n","Lancester Stemmer's output: work\n","Porter Stemmer's output: zero\n","Lancester Stemmer's output: zero\n","Porter Stemmer's output: graviti\n","Lancester Stemmer's output: grav\n","Porter Stemmer's output: ,\n","Lancester Stemmer's output: ,\n","Porter Stemmer's output: upsid\n","Lancester Stemmer's output: upsid\n","Porter Stemmer's output: ,\n","Lancester Stemmer's output: ,\n","Porter Stemmer's output: underwat\n","Lancester Stemmer's output: underw\n","Porter Stemmer's output: ,\n","Lancester Stemmer's output: ,\n","Porter Stemmer's output: almost\n","Lancester Stemmer's output: almost\n","Porter Stemmer's output: surfac\n","Lancester Stemmer's output: surfac\n","Porter Stemmer's output: includ\n","Lancester Stemmer's output: includ\n","Porter Stemmer's output: glass\n","Lancester Stemmer's output: glass\n","Porter Stemmer's output: also\n","Lancester Stemmer's output: also\n","Porter Stemmer's output: enjoy\n","Lancester Stemmer's output: enjoy\n","Porter Stemmer's output: modest\n","Lancester Stemmer's output: modest\n","Porter Stemmer's output: success\n","Lancester Stemmer's output: success\n","Porter Stemmer's output: novelti\n","Lancester Stemmer's output: novel\n","Porter Stemmer's output: item\n","Lancester Stemmer's output: item\n","Porter Stemmer's output: back\n","Lancester Stemmer's output: back\n","Porter Stemmer's output: earth\n","Lancester Stemmer's output: ear\n","Porter Stemmer's output: .\n","Lancester Stemmer's output: .\n","Porter Stemmer's output: the\n","Lancester Stemmer's output: the\n","Porter Stemmer's output: soviet\n","Lancester Stemmer's output: soviet\n","Porter Stemmer's output: union\n","Lancester Stemmer's output: un\n","Porter Stemmer's output: ,\n","Lancester Stemmer's output: ,\n","Porter Stemmer's output: face\n","Lancester Stemmer's output: fac\n","Porter Stemmer's output: problem\n","Lancester Stemmer's output: problem\n","Porter Stemmer's output: ,\n","Lancester Stemmer's output: ,\n","Porter Stemmer's output: use\n","Lancester Stemmer's output: us\n","Porter Stemmer's output: pencil\n","Lancester Stemmer's output: pencil\n","Porter Stemmer's output: .\n","Lancester Stemmer's output: .\n","Porter Stemmer's output: thi\n","Lancester Stemmer's output: thi\n","Porter Stemmer's output: funniest\n","Lancester Stemmer's output: funniest\n","Porter Stemmer's output: joke\n","Lancester Stemmer's output: jok\n","Porter Stemmer's output: ever\n","Lancester Stemmer's output: ev\n","Porter Stemmer's output: .\n","Lancester Stemmer's output: .\n","during\n","heat\n","space\n","race\n","1960\n","'s\n",",\n","nasa\n","quickly\n","discovered\n","ballpoint\n","pen\n","would\n","work\n","zero\n","gravity\n","confines\n","space\n","capsule\n",".\n","after\n","considerable\n","research\n","development\n",",\n","astronaut\n","pen\n","developed\n","cost\n","$\n","1\n","million\n",".\n","the\n","pen\n","worked\n","zero\n","gravity\n",",\n","upside\n",",\n","underwater\n",",\n","almost\n","surface\n","including\n","glass\n","also\n","enjoyed\n","modest\n","success\n","novelty\n","item\n","back\n","earth\n",".\n","the\n","soviet\n","union\n",",\n","faced\n","problem\n",",\n","used\n","pencil\n",".\n","this\n","funniest\n","joke\n","ever\n",".\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}]}]}